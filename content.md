## ベイズ統計モデリング輪読会#6
### 第11章 帰無仮説有意性検定
<br>
goto

========================================
### Outline
- - -
1. <font color="Purple">自己紹介</font>

1. 11-1章 善意で舗装された道

1. 11-2章 事前分布

1. 11-3章 信頼区間と最高密度区間

1. 11-4章 多重比較

1. 11-5章 サンプリング分布が役に立つこと

========================================
### <font color="Purple">自己紹介</font>
- - -
- <font color="Purple">名前：goto</font>
<br><br>
- <font color="Purple">勤務先：車メーカー（昨年12月に転職）</font>
<br><br>
- <font color="Purple">犬四匹本のやや抽象的で詩的な文体は、実はそんなに嫌いじゃない</font>
<br><br>
- <font color="Purple">勉強会は初めて参加。発表も人生初</font>
<br><br>
- <font color="Purple">よろしくお願いします</font>

========================================
## 　　　11-1章 善意で舗装された道
### <font color="Purple">悪気はなくとも悪事を犯す、<br>そんな危険な橋は渡るべきではない。（by 小杉先生）</font>

========================================
### 帰無仮説有意性検定(NHST)とは？
- - -
Null Hypothesis Significance Testingの略。<br>
頻度主義の手法であり、次の手続きで行われる。

1. 検証したい帰無仮説を設定する<br>
「コインの表が出る確率$\theta$は$0.5$である」

1. 実験してデータを集める<br>
「コイントス$24$回中、表が出たのは$7$回でした」

1. $p$値を計算する<br>
※意味と計算方法は後述

1. 帰無仮説を棄却するか判定する<br>
「$p$値が$2.5\%$より小さいので、仮説は棄却される」<br>
「$p$値が$2.5\%$より大きいので、仮説は棄却されない」

========================================
### $p$値とは、得られたデータの「極端さ」の指標
- - -
$p$値の定義：ある帰無仮説が正しい場合に、実際にサンプリングされたデータよりもさらに「極端」なデータが得られる確率

$$
p値 =p\(D\_{\theta,I} \succeq D\_{実際}|\theta,I\) \\
$$
<br>
$D$: 記述統計量。コインの場合は(表の出た回数$z$)/(コイントス回数$N$)<br>
$\theta$: 検証したい帰無仮説のパラメタ<br>
$I$: サンプリング方法を決める意図(後述)<br>
$\succeq$:左の$D$が右の$D$よりも「極端である」ことを表す<br>

コイントスの場合を具体的に書くと
\begin{eqnarray}
p\(右端\)=p\( (z/N)\_{\theta,I} \ge (z/N)\_{実際} |\theta,I\)
\\\
p\(左端\)=p\( (z/N)\_{\theta,I} \le (z/N)\_{実際} |\theta,I\)
\end{eqnarray}

========================================
### 実際に$p$値を計算してみる
- - -
実験者「$\theta=0.5$だと思うんだけど、実験してくれない？」<br>
助手　「分かりました。」<br>
　　　（$2$分後）<br>
助手　「実験の結果が出ました。<br>
　　　　裏裏表表裏裏表裏裏裏裏裏裏裏裏裏表裏裏表表裏裏表」<br>
実験者「$24$回中$7$回表が出たわけか。<br>
　　　　トスの回数はどういう意図で決めたの？」<br>

助手の意図として、次のパターンを考える<br>
1. 「トス回数$N$が$24$になったらやめよう、と最初から決めてました。」<br>
1. 「表回数$z$が$7$になったらやめよう、と最初から決めてました。」<br>
1. 「$2$分たったらやめよう、最初から決めてました。」<br>

----------------------------------------
### サンプリング空間
- - -
サンプリング意図を細かく気にする理由は、<br>
意図次第でサンプリング空間が変わるから！

========================================
### 意図1:トス回数$N$を固定した場合[1/2]
- - -
$N$を固定した時に表が$z$回出る確率は、次の二項分布に従う。
$$
p(z|N,\theta)=
\begin{pmatrix}
N \\\
z
\end{pmatrix}
\theta^z
\(1-\theta\)^{N-z}
$$

$p$値はグラフ中の+矢印部分を足しあげた値$3.2\%$となる。
<!-- ここにグラフ入れる -->

========================================
### 意図1:トス回数$N$を固定した場合[2/2]
- - -
$p$値と比較する閾値には、慣習的に両側$5\%$を使う。

今回は$z/N$が極端に小さいかどうか（＝分布の左裾側に外れているか）を検定したいので、片側確率$2.5\%$と比較する。

$p$値$=3.2\%>2.5\%$より、帰無仮説「$\theta=0.5$」の元で$z=7$は極端とは判定されない。
よって、帰無仮説は棄却されない。<br>
(※「採択する」ほど強い主張ではない)

----------------------------------------
### $p$値計算時の注意
- - -
$p$値は得られたデータの確率$p(z=7)$ではなく、<br>
得られたデータ<font color="Red">よりも極端な</font>データが得られる確率$p(z\le7)$。

確率をそのまま使うと良くない例：<br>
$\theta=0.5$のコイントスを$1000$回やった場合、最も可能性が大きい$z$の値は$500$。
でも$p\(z=500\)$は$2.5\%$と、非常に小さい。

----------------------------------------
### 実際にプロット比較してみた
- - -
<img src="img/pic11_3_N24.png"   alt="Drawing" style="width: 400px;" align="center"/>
<img src="img/pic11_3_N1000.png" alt="Drawing" style="width: 400px;" align="center"/>

========================================
### 意図2:表の回数$z$を固定した場合[1/2]
- - -
$N$回目のトスで$z$回目の表が出る
<br>
＝$N-1$回目までのトスで$z-1$回表が出ており、次のトスで表が出る
\begin{eqnarray}
p(N|z,\theta)
&=&
\begin{pmatrix}
N-1 \\\ z - 1
\end{pmatrix}
\theta^{z-1} (1-\theta)^{\\{(N-1)-(z-1)\\}}
\ \ \ \times \theta
\\\
&=&
\frac{z}{N}
\begin{pmatrix}
N \\\ z
\end{pmatrix}
\theta^{z} (1-\theta)^{N-z}
\end{eqnarray}

<!-- ここにグラフ入れる -->

========================================
### 意図2:表の回数zを固定した場合[2/2]
- - -
$p$値$=3.2\%>1.7\%$なので、つまり帰無仮説「$\theta=0.5$」を主張するにしては得られたデータがあまりに極端。仮説は棄却される。

<font color="Red">
サンプリング意図が変わると結果も変わる！
</font>

----------------------------------------
### 実は、$z$を固定する方法はあまり良くない。
- - -
サンプリングの後半に出てくるかもしれない補償的なデータを捨てるので、バイアスがかかる。

<font color="Purple">
例：<br>
「コイントスの結果$1000$回中$500$回表が出たが、表は前半に偏った」
</font>

========================================
### 意図3:制限時間を固定した場合[1/2]
- - -
この場合は$N$も$z$も共に確率変数。

決められた時間内でのイベント発生回数はポアソン分布でモデル化。<br>
$$
p(N|\lambda) = \frac{\lambda^{N}e^{-\lambda}}{N!}
\ \ \ \ \ \(N>0\)
$$
(パラメタ$\lambda$は分布の平均。今回は$24$とする)<br>
　　　　　　　　　
<img src="img/pic11_5_poisson.png"   alt="Drawing" style="width: 300px;"/>

$N$がポアソン分布で決まり、その$N$に対して$z$が二項分布で決まる。<br>
<font color="Purple">($z$が$N$に従属する階層ベイズモデル)</font>

========================================
### 意図3:制限時間を固定した場合[2/2]
- - -

$p$値$=2.4\%<2.5\%$となり帰無仮説「$\theta=0.5$」は棄却されるが、これを信じて良いものか？

今回は$\lambda$として$24$を設定したが、もしコイントス$1$回平均$6$秒ならば$\lambda$は$20$とすべきで、その場合$p$値は$3.5\%$になる(検定結果がアッサリ変わる)

さらに、ポアソン分布は$N=\infty$でも有限の値をもつが、$2$分間に$\infty$回コイントスはできない。

→NHSTでは仮想的なサンプリング分布をベースとするので、<br>
　意図が変わればサンプリング分布が変わり、$p$値も変わる。


========================================
### 複数の検定を行う場合
- - -
帰無仮説「$\theta=0.5$」。$N=24$固定で$7$回表が出た。
ここまでは意図1と同じだが、<font color="Red">同じ実験を行うコインがもう$1$枚ある。</font>


左側$p$値：[コイン$1$の極端さ]ではなく[コイン$1$,$2$合わせた極端さ]
<br><br>
\begin{eqnarray}
p\(
  \(z\_1/N\_1\)\_{\theta\_1,I\_1}
  \le
  (z\_1/N\_1\)\_{実際}
  あるいは
  \(z\_2/N\_2\)\_{\theta\_2,I\_2}
  \le
  (z\_1/N\_1\)\_{実際}
  |
  \theta\_1,\theta\_2,I\_1,I\_2
\)
\end{eqnarray}

<br>
→$p$値は<font color="Red">$6.3\%$</font>（※コイン$1$枚のときは<font color="Red">$3.2\%$</font>）

<font color="Red">
実際に$2$枚目のコインは振っていないが、振ろうという意図の存在によって仮想的な可能性が広がったのが原因。
$1$枚目の結果が極端でも、$2$枚目が極端でなければ仮説「$\theta=0.5$」を棄却できないと考える。
</font>

----------------------------------------

### <font color="Purple">コイン以外の例：レアカードのゲット率[1/2]</font>
- - -
<font color="Purple">
レアカードの割合＝$20$パックに1枚
<br><br>
貧乏なＡ君：$1$パックだけ購入。レアカードが出た<br>
金持ちＢ君：$20$パック購入。$1$パック目を開けたらレアカードが出た
<br><br>
Ａ君のパターンとＢ君のパターン、どちらが「極端」？
</font>

----------------------------------------

### <font color="Purple">コイン以外の例：レアカードのゲット率[2/2]</font>
- - -
<font color="Purple">
NHST：<br><br>
貧乏なＡ君パターンの方が極端。Ａ君のレア率は$1/1$。大してＢ君の買った残り$19$パックは全てハズレの可能性があり、その場合はレア率$1/20$だから、封入率$1/20$からして別に珍しい経験でも何でもない。
<br><br><br>
ベイジアン分析：<br><br>
どちらも極端さは同じ。「$1$パック開封してレアが出た」という事実には何の差もない。
</font>

========================================
### 意図によって変動する$p$値を信用していいものか
- - -
- $N$を十分に大きくすれば問題ないのでは？<br>
→$N$が小さい時は何の情報も得られないことになるし、$N$が大きくとも$p$値が意図に大きく影響を受ける場合はある。

- 最初から$N$固定を意図していた、と常に考えればよいのでは？<br>
→$z$固定などの他の意図を否定できていない。

意図に依存してしまう  NHSTではなく、観測データにのみ依存するベイジアン分析をやるべきである！

========================================
## 　　　　　　11-2章 事前分布
### 　　　　<font color="Purple">経験知識をモデルに組み込みましょう</font>

========================================
### 事前知識の大切さ(1/2)
- - -
ここまでのNHSTモデルは、コインではなく釘の場合も全く同じ。

　　　　　<img src="img/nailHead.jpg"   alt="Drawing" style="width: 150px;" align="top"/>
　　　　　　　
<img src="img/nailTail.jpg"   alt="Drawing" style="width: 250px;" align="top"/>
<br>
　　　　　↑釘の「表」　　　　　　　　↑釘の「裏」

コインの表が$24$回中$7$回と、釘の表が$7/24$の$24$回中$7$回で、<br>
極端さは同じか？

========================================
### 事前知識の大切さ(2/2)
- - -
<!-- 図11.7 -->
「釘は表が出にくい」という事前知識を取り込むべき。

事前知識は意図とは違い、経験データにとことん向き合って得られた明白かつ適切な知識である！

========================================
## 　　11-3章 信頼区間と最高密度区間
### 　　　　<font color="Purple">頻度主義からの反論に対する反論</font>

========================================
### 頻度主義からの反論：信頼区間の利用[1/2]
- - -

棄却されるorされないの結論ではなく、NHSTで棄却されない帰無仮説の$\theta$範囲（信頼区間）を利用すればいいのでは？

$N=24$固定で$z=7$が得られた時の$95\%$信頼区間は$\[0.126,0.511\]$
<!-- 11.10 -->

========================================
### 頻度主義からの反論：信頼区間の利用[2/2]
- - -

信頼区間を使っても、意図によって結果が変わる問題が残る。<br>
これは信頼区間の定義自体に$p$値が含まれているため、必然。

| No. | 意図 | $95\%$信頼区間 |
| --- | --- | --- |
| 1 | $N$固定 | $\[0.126,0.511\]$ |
| 2 | $z$固定 | $\[0.126,0.484\]$ |
| 3 | 時間固定 | $\[0.135,0.497\]$ |
| 4 | $N$固定でコイン$2$枚 | $\[0.110,0.539\]$ |

----------------------------------------
### 注意：信頼区間は$\theta$の「分布」ではない
- - -

実際、積分しても$1$にならない
<!-- p vs theta -->

========================================
### 信頼区間とベイズ最高密度区間(HDI)の違い
- - -

似た概念であるベイズHDI（$4$章）は、事後確率$95\%$を占める$\theta$の範囲。

利点は次の$3$つ

1. 「$p\(\theta|D\)$に基づく$\theta$の確信度」という意味付けが可能
1. 意図に依存しない
1. 事前の信念を取り込むことができる

----------------------------------------
### ：信頼区間は$\theta$の「分布」ではない
- - -

========================================
## 　　　　　　11-4章 多重比較
### 　　　　　　　　<font color="Purple">NHSTよ、さようなら</font>

========================================
### 比較パターンが増えることの影響[1/2]
- - -

#### 例：内野と外野の選手にバッティング能力の差は無いか？

①大雑把な人：平均だけ比べれば良いだろう…

→内野平均vs外野平均

<br>
②細かい人：内野手の中でもピッチャーとキャッチャーは特別。
内野手というくくりを、ピッチャー,キャッチャー,内野手に細分化すべきだ


→外野手vs非外野手、外野手vs内野手、外野手vsキャッチャーピッチャー平均、内野手bsキャッチャーピッチャー平均

========================================
### 比較パターンが増えることの影響[2/2]
- - -

検定数を増やすと、仮想的なサンプリング空間が広がる<br>
→$p$値を増加させてしまう！

<font color="Purple">
「検定数が増えれば、極端な結果がたまに出てもおかしくはない」
</font>
<br><br><br><br>
<font color="Red">
悪いことに、検定数をどこまで増やすかは実験者の意図に依存する
</font>

========================================
### ベイズの事後分布は１つだけ！
- - -

複数の検定は、おなじ事後分布を複数の視点からみる事に相当。
<br>
事後分布は唯一無二であり、意図によって変動しない

========================================
## 　11-5章 サンプリング分布が役に立つこと
<font color="Purple">
それでも、仮想的なサンプリング分布可能性に意味があるとすれば…
</font>

========================================
### サンプリング分布の使い方①<br>実験を計画する
- - -

実験前に予め仮想のサンプリング分布でシミュレーションすることで<br>
検定に適した実験方法をデザインできるかもしれない。

（当然、シミュレーション結果はベイズの枠組で分析する）


========================================
### サンプリング分布の使い方②<br>事後予測チェック
- - -

ベイジアン分析が提示するのは、モデルの<font color="Red">相対的</font>な確信度。

例：<br>$40$回中$30$回表が出たコインに対しては
$\theta=99\%$のモデルは$\theta=1\%$のモデルより相対的に優れているが、$\theta=99\%$が適切とは到底いえない

→実際の有用性を知る方法として、サンプリング分布を使う。

シミュレーション結果と実際の結果が類似するならば、<br>
そのモデルはそれなりに妥当といえる

========================================
# <font color="Purple">結論</font>
<br>
### <font color="Purple">帰無仮説ではなく、</font>
### <font color="Purple">帰するべき事前分布を設定しよう！</font>
<br>
### 　　　　　　　　　　　　　　　　　　　　〜おわり〜
