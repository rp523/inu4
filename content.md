## ベイズ統計モデリング輪読会#6
### 第11章 帰無仮説有意性検定
<br>
goto

========================================
### Outline
- - -
1. <font color="Purple">自己紹介</font>

1. 11-1章 善意で舗装された道

1. 11-2章 事前分布

1. 11-3章 信頼区間と最高密度区間

1. 11-4章 多重比較

1. 11-5章 サンプリング分布が役に立つこと

========================================
### <font color="Purple">自己紹介</font>
- - -
- <font color="Purple">名前： 　 goto</font>
<br><br>
- <font color="Purple">勤務先：　車メーカー（昨年12月に転職）</font>
<br><br>
- <font color="Purple">勉強会：　参加したのはここが初めてです。発表は人生初</font>

========================================
## 　　　11-1章 善意で舗装された道
### 　　　　　　<font color="Purple">ここがヘンだよNHST</font>

========================================
### 帰無仮説有意性検定(NHST)とは？
- - -
Null Hypothesis Significance Testingの略。<br>
頻度主義の手法であり、次の手続きで行われる。

1. 検証したい帰無仮説を設定する<br>
「コインの表が出る確率$\theta$は$0.5$である」

1. $p$値を計算する<br>
※$p$値の意味と計算方法は後述

1. $p$値が閾値より小：仮説は棄却<br>
$p$値が閾値より大：仮説は棄却されない

========================================
### 得られたデータの「極端さ」の指標：$p$値
- - -
$p$値の定義：ある帰無仮説が正しい場合に、実際にサンプリングされたデータよりもさらに「極端」なデータが得られる確率

$$
p値 =p\(D\_{\theta,I} \succeq D\_{実際}|\theta,I\) \\
$$
<br>
$D$: 記述統計量。コインの場合は(表の出た回数$z$)/(コイントス回数$N$)<br>
$\theta$: 検証したい帰無仮説のパラメタ<br>
$I$: サンプリング方法を決める意図(後述)<br>
$\succeq$:左の$D$が右の$D$よりも「極端である」ことを表す<br>

コイントスの場合を具体的に書くと
\begin{eqnarray}
p\(右端\)=p\( (z/N)\_{\theta,I} \ge (z/N)\_{実際} |\theta,I\)
\\\
p\(左端\)=p\( (z/N)\_{\theta,I} \le (z/N)\_{実際} |\theta,I\)
\end{eqnarray}

========================================
### 3種類のサンプリング意図$I$ごとに$p$値を計算してみる
- - -
実験者「$\theta=0.5$だと思うんだけど、実験してくれない？」<br>
助手　「分かりました。」<br>
　　　（$2$分後）<br>
助手　「実験の結果が出ました。<br>
　　　　裏裏表表裏裏表裏裏裏裏裏裏裏裏裏表裏裏表表裏裏表」<br>
実験者「$24$回中$7$回表が出たわけね。<br>
　　　　トスの回数はどういう意図で決めたの？」<br>

助手の意図として、次のパターンを考えてみる<br>
1. 「トス回数$N$が$24$になったらやめよう、と最初から決めてました。」<br>
1. 「表回数$z$が$7$になったらやめよう、と最初から決めてました。」<br>
1. 「$2$分たったらやめよう、最初から決めてました。」<br>

----------------------------------------
### サンプリング空間
- - -
サンプリング意図を細かく気にする理由は、<br>
意図次第でサンプリング空間が変わるから！

========================================
### 意図1:トス回数$N$を固定した場合(1/2)
- - -
$N$を固定した時に表が$z$回出る確率は、次の二項分布に従う。
$$
p(z|N,\theta)=
\begin{pmatrix}
N \\\
z
\end{pmatrix}
\theta^z
\(1-\theta\)^{N-z}
$$

$p$値はグラフ中の+矢印部分を足しあげた値$3.2\%$となる。
<!-- ここにグラフ入れる -->

----------------------------------------
### $p$値計算時の注意
- - -
$p$値は
$$
p(z=7|N=24,\theta=0.5)=2.063\%
$$
ではなく
$$
\sum_{z=1}^{7} p(z|N=24,\theta=0.5)=3.2\%
$$
が正しい。単一の$z$の確率だけでは極端さを評価できないため。

例えば$N=1000$の場合は、$\theta=0.5$が正しかったとしても$z=500$となる確率は$2.5\%$だが、明らかにこの値の小ささだけで極端と判定すべきではない。

----------------------------------------
### 実際にプロット比較してみた
- - -
<img src="img/pic11_3_N24.png"   alt="Drawing" style="width: 400px;" align="center"/>
<img src="img/pic11_3_N1000.png" alt="Drawing" style="width: 400px;" align="center"/>

========================================
### 意図1:トス回数$N$を固定した場合(2/2)
- - -
$p$値と比較する閾値には、慣習的に両側$5\%$を使う。

今回は$z/N$が極端に小さいかどうか（＝分布の左裾側に外れているか）を検定したいので、片側確率$2.5\%$と比較する。

$p=3.2\%>2.5\%$より、帰無仮説「$\theta=0.5$」の元で$z=7$は極端とは判定されない。
よって、帰無仮説は棄却されない。<br>
(※「採択する」ほど強い主張ではない)
<!-- ここにグラフ入れる -->

========================================
### 意図2:表の回数$z$を固定した場合(1/2)
- - -
$N$回目のトスで$z$回目の表が出る
<br>
＝$N-1$回目までのトスで$z-1$回表が出ており、次のトスで表が出る
\begin{eqnarray}
p(N|z,\theta)
&=&
\begin{pmatrix}
N-1 \\\ z - 1
\end{pmatrix}
\theta^{z-1} (1-\theta)^{\\{(N-1)-(z-1)\\}}
\ \ \ \times \theta
\\\
&=&
\frac{z}{N}
\begin{pmatrix}
N \\\ z
\end{pmatrix}
\theta^{z} (1-\theta)^{N-z}
\end{eqnarray}

<!-- ここにグラフ入れる -->
<font color="Purple">
※ビンゴゲームと同じ考え方
</font>

========================================
### 意図2:表の回数zを固定した場合(2/2)
- - -
$p$値は$1.7\%$。片側閾値$2.5\%$より小さい。

つまり帰無仮説「$\theta=0.5$」が正しいと主張するには、得られたデータがあまりに極端。
仮説は棄却される。

<font color="Red">
サンプリング意図が変わると結果も変わる！
</font>

----------------------------------------
### 実は、$z$を固定する方法はあまり良くない。
- - -
サンプリングの後半に出てくるかもしれない補償的なデータを捨てるので、バイアスがかかる。

========================================
### 意図3:制限時間を固定した場合(1/2)
- - -
この場合は$N$も$z$も共に確率変数。

発生確率一定の事象が決められた時間内で発生する回数はポアソン分布
$$
p(N|\lambda) = \frac{\lambda^{N}e^{-\lambda}}{N!}
\ \ \ \ \ \(N>0\)
$$
でモデル化する。(パラメタ$\lambda$は分布の平均。今回は$24$とする)
　　　　　　　　　
<img src="img/pic11_5_poisson.png"   alt="Drawing" style="width: 300px;"/>

$N$がポアソン分布で決まり、その$N$に対して$z$が二項分布で決まる。
<font color="Purple">($z$が$N$に従属する階層ベイズモデル)</font>

========================================
### 意図3:制限時間を固定した場合(2/2)
- - -

結果、$p$値は$2.4\%$となり、片側閾値$2.5\%$よりわずかに小さく帰無仮説「$\theta=0.5$」は棄却されるが、これを信じて良いものか？

今回は$N$の平均として$24$を設定したが、コイントス$1$回平均$6$秒とすれば平均は$20$とすべきで、その場合$p$値は$3.5\%$になる(検定結果が変わる)

さらに、ポアソン分布は$N=\infty$でも有限の値をもつが、$2$分間に$\infty$回コイントスはできない。

→他にもパラメタは色々あり、いくらでもサンプル集合は変わる。<br>
　サンプル集合が変われば$p$値も変わる。

========================================
### 複数の検定を行う場合
- - -
帰無仮説「$\theta=0.5$」。$N=24$固定で$7$回表が出た。
<font color="Red">同じコインがもう$1$枚ある。</font>


左側$p$値：[コイン$1$の極端さ]ではなく[コイン$1$,$2$合わせた極端さ]
<br><br>
\begin{eqnarray}
p\(
  \(z\_1/N\_1\)\_{\theta\_1,I\_1}
  \le
  (z\_1/N\_1\)\_{実際}
  あるいは
  \(z\_2/N\_2\)\_{\theta\_2,I\_2}
  \le
  (z\_1/N\_1\)\_{実際}
  |
  \theta\_1,\theta\_2,I\_1,I\_2
\)
\end{eqnarray}

<br>
→$\(z\_1/N\_1\)_{実際}=7/24$の$p$値は<font color="Red">$6.3\%$</font>（※コイン$1$枚のときは<font color="Red">$3.2\%$</font>）

<font color="Red">
実際に$2$枚目のコインは振っていないが、振ろうという意図の存在によって仮想的な可能性が広がったのが原因。
$1$枚目の結果が極端でも、$2$枚目が極端でなければ仮説「$\theta=0.5$」を棄却できないと考える。
</font>

----------------------------------------

### <font color="Purple">コイン以外の例：レアカードのゲット率[1/2]</font>
- - -
<font color="Purple">
レアカードの割合＝$20$パックに1枚
<br><br>
貧乏なＡ君：$1$パックだけ購入。レアカードが出た<br>
金持ちＢ君：$20$パック購入。$1$パック目でレアカードが出た
<br><br>
Ａ君のラッキーとＢ君のラッキー、どちらが起こりにくい？
</font>

----------------------------------------

### <font color="Purple">コイン以外の例：レアカードのゲット率[2/2]</font>
- - -
<font color="Purple">
NHST：<br><br>
貧乏なＡ君の経験の方が起こりにくい。Ａ君のレア率は$1/1$。大してＢ君の買った残り$19$パックは全てハズレの可能性があり、その場合はレア率$1/20$だから、封入率$1/20$からして別に珍しい経験でも何でもない。
<br><br><br>
ベイジアン分析：<br><br>
どちらも起こりにくさは同じ。「$1$パック開封してレアが出た」という事実には何の差もない。
</font>

========================================
### 意図によって変動する$p$値を信用していいものか
- - -
- $N$を十分に大きくすれば問題ないのでは？<br>
→$N$が小さい時は何の情報も得られないことになるし、$N$が大きくとも$p$値が意図に大きく影響を受ける場合はある。

- 最初から$N$固定を意図していた、と常に考えればよいのでは？<br>
→$z$固定などの他の意図を否定できていない。

意図に依存してしまう  NHSTではなく、観測データにのみ依存するベイジアン分析をやるべきである！

========================================
## 　　　　　　11-2章 事前分布
### 　　　　<font color="Purple">経験知識をモデルに組み込みましょう</font>

========================================
### 事前知識の大切さ(1/2)
- - -
ここまでのNHSTモデルは、コインではなく釘の場合も全く同じ。

コインの表回数が$7/24$回の極端さと、釘表が$7/24$の極端さは同じか？

  <img src="img/nailHead.jpg"   alt="Drawing" style="width: 150px;" align="top"/>
<br>
↑釘をトスしたときの「表」

========================================
### 事前知識の大切さ(2/2)
- - -
<!-- 図11.7 -->
私達が持っている「釘は表が出にくい」という事前知識を取り込むべき。

事前知識は意図とは違い、経験データにとことん向き合って得られた明白かつ適切な知識である！

========================================
## 　　11-3章 信頼区間と最高密度区間
### 　　　　<font color="Purple">頻度主義からの反論に対する反論</font>

========================================
### 頻度主義からの反論：信頼区間の利用
- - -

信頼区間：NHSTで棄却されない帰無仮説の範囲

$N=24$固定で$z=7$が得られた時の$95\%$信頼区間は$\theta \[0.126,0.511\]$
<!-- 11.10 -->

========================================
### 信頼区間の利用
- - -

信頼区間を使っても、意図によって結果が変わる問題が残る。<br>
これは信頼区間の定義自体に$p$値が含まれているため、必然。

| No. | 意図 | $95\%$信頼区間 |
| --- | --- | --- |
| 1 | $N$固定 | $\[0.126,0.511\]$ |
| 2 | $z$固定 | $\[0.126,0.484\]$ |
| 3 | 時間固定 | $\[0.135,0.497\]$ |
| 4 | $N$固定でコイン$2$枚 | $\[0.110,0.539\]$ |

----------------------------------------
### 注意：信頼区間は$\theta$の「分布」ではない
- - -

実際、積分しても$1$にならない
<!-- p vs theta -->

========================================
### 信頼区間とベイズ最高密度区間(HDI)の違い
- - -

ベイズHDI（$4$章で登場）は、事後確率$95\%$を占める$\theta$の範囲。

利点は次の$3$つ

1. 「$p\(\theta|D\)$に基づく$\theta$の確信度」という意味付けが可能
1. 意図に依存しない
1. 事前の信念を取り込むことができる

----------------------------------------
### ：信頼区間は$\theta$の「分布」ではない
- - -

========================================
## 　　　　　　11-4章 多重比較
### 　　　　　　　　<font color="Purple">NHSTよ、さようなら</font>

========================================
### 比較パターンが増えることの影響
- - -

検定数を増やすと、仮想的なサンプリング空間が広がる<br>
→$p$値を増加させてしまう！

<font color="Purple">
検定数が増えれば、ラッキーパンチもたまには出ちゃうだろう
</font>
<br><br><br><br>
<font color="Red">
悪いことに、検定数をどこまで増やすかは実験者の意図に依存する
</font>

----------------------------------------
### 例：内野と外野の選手にバッティング能力の差は無いか？
- - -

大雑把な人：平均だけ比べれば良いだろう…

→内野平均vs外野平均

<br>
細かい人：内野手の中でもピッチャーとキャッチャーは特別。
内野手というくくりを、ピッチャー,キャッチャー,内野手に細分化すべきだ


→外野手vs非外野手、外野手vs内野手、外野手vsキャッチャーピッチャー平均、内野手bsキャッチャーピッチャー平均

========================================
### ベイズの事後分布は１つだけ！
- - -

複数の検定は、単一の事後分布を複数の視点からみる事に相当。
<br>
事後分布は唯一無二であり、意図によって変動しない

========================================
## 　11-5章 サンプリング分布が役に立つこと
<font color="Purple">
 　　　　　それでも、仮想可能性に意味があるとすれば…
</font>

========================================
### サンプリング分布の使い方①<br>実験を計画する
- - -

実験前に予め仮想のサンプリング分布でシミュレーションすることで<br>
検定に適した実験方法をデザインできるかもしれない。

（当然、シミュレーション結果はベイズの枠組で分析する）


========================================
### サンプリング分布の使い方②<br>事後予測チェック
- - -

ベイジアン分析が提示するのは、モデルの<font color="Red">相対的</font>な確信度。

例：<br>$40$回中$30$回表が出たコインに対しては
$\theta=99\%$のモデルは$\theta=1\%$のモデルより相対的に優れているが、$\theta=99\%$が適切とは到底いえない

→実際の有用性を知る方法として、サンプリング分布を使う。

シミュレーション結果と実際の結果が類似するならば、<br>
そのモデルはそれなりに妥当といえる

========================================
# <font color="Purple">結論</font>
<br>
### <font color="Purple">帰無仮説ではなく、</font>
### <font color="Purple">帰するべき事前分布を設定しよう！</font>
<br>
### 　　　　　　　　　　　　　　　　　　　　〜おわり〜
